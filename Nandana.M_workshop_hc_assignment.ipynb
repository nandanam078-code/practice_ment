{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60dde93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß WORKSHOP ENVIRONMENT CHECK\n",
      "============================================================\n",
      "üìã Checking required libraries and versions:\n",
      "--------------------------------------------------\n",
      "‚úÖ langchain: 0.3.27\n",
      "‚úÖ langchain_community: 0.3.29\n",
      "‚úÖ chromadb: 1.2.1\n",
      "‚úÖ pypdf: 6.1.3\n",
      "‚úÖ numpy: 2.3.3\n",
      "‚úÖ pathlib: built-in\n",
      "‚úÖ os: built-in\n",
      "‚úÖ sys: built-in\n",
      "\n",
      "ü§ñ Checking Ollama setup:\n",
      "------------------------------\n",
      "‚úÖ Ollama: Installed and phi3:mini model available\n",
      "\n",
      "‚úÖ ALL LIBRARIES INSTALLED!\n",
      "üöÄ Ready to proceed with the workshop!\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# PART 0: ENVIRONMENT SETUP AND LIBRARY VERSION CHECK\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Verify environment setup and library compatibility\n",
    "\n",
    "def check_library_versions():\n",
    "    \"\"\"\n",
    "    WORKSHOP FUNCTION: Environment Verification\n",
    "    \n",
    "    PURPOSE: Check installed library versions for compatibility\n",
    "    This helps ensure all students have the same environment setup\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"üîß WORKSHOP ENVIRONMENT CHECK\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    required_libraries = {\n",
    "        'langchain': '0.3.27',\n",
    "        'langchain_community': '0.3.29',\n",
    "        'chromadb': '1.0.20',\n",
    "        'pypdf': '6.0.0',\n",
    "        'numpy': '6.0.0',\n",
    "        'pathlib': 'built-in',\n",
    "        'os': 'built-in',\n",
    "        'sys': 'built-in'\n",
    "    }\n",
    "    \n",
    "    print(\"üìã Checking required libraries and versions:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    missing_libraries = []\n",
    "    version_mismatches = []\n",
    "    \n",
    "    for library, min_version in required_libraries.items():\n",
    "        try:\n",
    "            if library in ['pathlib', 'os', 'sys']:\n",
    "                print(f\"‚úÖ {library}: {min_version}\")\n",
    "                continue\n",
    "                \n",
    "            if library == 'langchain':\n",
    "                import langchain\n",
    "                version = langchain.__version__\n",
    "            elif library == 'langchain_community':\n",
    "                import langchain_community\n",
    "                version = getattr(langchain_community, '__version__', 'unknown')\n",
    "            elif library == 'chromadb':\n",
    "                import chromadb\n",
    "                version = chromadb.__version__\n",
    "            elif library == 'pypdf':\n",
    "                import pypdf\n",
    "                version = pypdf._version.__version__\n",
    "            elif library == 'numpy':\n",
    "                import numpy\n",
    "                version = numpy.__version__\n",
    "            \n",
    "            print(f\"‚úÖ {library}: {version}\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(f\"‚ùå {library}: NOT INSTALLED\")\n",
    "            missing_libraries.append(library)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  {library}: Error checking version - {e}\")\n",
    "    \n",
    "    # Check Ollama availability (external dependency)\n",
    "    print(\"\\nü§ñ Checking Ollama setup:\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            if 'phi3:mini' in result.stdout:\n",
    "                print(\"‚úÖ Ollama: Installed and phi3:mini model available\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  Ollama: Installed but phi3:mini model missing\")\n",
    "                print(\"   Run: ollama pull phi3:mini\")\n",
    "        else:\n",
    "            print(\"‚ùå Ollama: Not properly configured\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Ollama: Not installed\")\n",
    "        print(\"   Install from: https://ollama.ai/\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚ö†Ô∏è  Ollama: Connection timeout - check if service is running\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Ollama: Error checking - {e}\")\n",
    "    \n",
    "    # Summary and installation commands\n",
    "    if missing_libraries:\n",
    "        print(f\"\\n‚ùå MISSING LIBRARIES: {', '.join(missing_libraries)}\")\n",
    "        print(\"\\nüì¶ EXACT INSTALLATION COMMANDS (Workshop Tested Versions):\")\n",
    "        print(\"pip install langchain==0.3.27\")\n",
    "        print(\"pip install langchain-community==0.3.29\")\n",
    "        print(\"pip install chromadb==1.0.20\")\n",
    "        print(\"pip install pypdf==6.0.0\")\n",
    "        print(\"pip install numpy==6.0.0\")\n",
    "        print(\"\\nRun these commands and restart the workshop.\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"\\n‚úÖ ALL LIBRARIES INSTALLED!\")\n",
    "        print(\"üöÄ Ready to proceed with the workshop!\")\n",
    "        return True\n",
    "\n",
    "# Run environment check\n",
    "environment_ready = check_library_versions()\n",
    "\n",
    "if not environment_ready:\n",
    "    print(\"\\n‚ö†Ô∏è  PLEASE INSTALL MISSING LIBRARIES BEFORE CONTINUING\")\n",
    "    print(\"Uncomment the sys.exit() line below if you want to stop here\")\n",
    "    # sys.exit(1)  # Students can uncomment this to stop execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf177a0",
   "metadata": {},
   "source": [
    "HANDS-ON RAG (Retrieval-Augmented Generation) WORKSHOP\n",
    "\n",
    "13 Oct 2025\n",
    "Ramaih University of Applied Sciences\n",
    "Instructor: Naganathan Muthuramalingam., PhD Scholar - School of Social Sciences\n",
    "\n",
    "This script demonstrates a complete end-to-end RAG system implementation.\n",
    "\n",
    "WHAT YOU'LL LEARN:\n",
    "1. Document Loading and Processing\n",
    "2. Text Chunking Strategies\n",
    "3. Vector Embeddings and Storage\n",
    "4. Retrieval Mechanisms\n",
    "5. LLM Integration\n",
    "6. Answer Validation and Grounding\n",
    "\n",
    "WORKSHOP STRUCTURE:\n",
    "- Part 0: Environment Setup and Library Version Check\n",
    "- Part 1: Imports and Document Discovery\n",
    "- Part 2: Document Loading and Text Chunking\n",
    "- Part 3: Vector Embeddings & Knowledge Base Creation\n",
    "- Part 4: Retrieval Configuration\n",
    "- Part 5: Language Model Setup\n",
    "- Part 6: Prompt Engineering for Grounding\n",
    "- Part 7: RAG Chain Assembly\n",
    "- Part 8: Answer Validation System\n",
    "- Part 9: Hands-on Testing\n",
    "\n",
    "SYSTEM REQUIREMENTS:\n",
    "- Minimum 8GB RAM (16GB recommended for better performance)\n",
    "- At least 20GB free disk space for models and vector databases\n",
    "- Python 3.8+ installed\n",
    "- Stable internet connection for initial model downloads\n",
    "- Ollama installed (https://ollama.ai/)\n",
    "- phi3:mini model downloaded via: ollama pull phi3:mini\n",
    "\n",
    "INSTALLATION STEPS:\n",
    "1. Install Python 3.8+\n",
    "2. Install Ollama from https://ollama.ai/\n",
    "3. Run: ollama pull phi3:mini\n",
    "4. Install required Python packages (see Part 0 below)\n",
    "5. Create 'data' folder and add PDF documents\n",
    "\n",
    "PREREQUISITES:\n",
    "- Basic Python knowledge\n",
    "- Understanding of machine learning concepts\n",
    "- Familiarity with NLP basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00efb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# PART 1: IMPORTS AND SETUP\n",
    "# ========================================================================\n",
    "# Standard library imports - Python's built-in modules\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain Document Loaders & Processing - For handling different document types\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Vector Store and Embeddings - For semantic search capabilities\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Local LLM via Ollama - For running language models locally\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# RAG Chain - For combining retrieval and generation\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663152a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 5 PDF(s):\n",
      " - data\\10-Tips-Healthy-Lifestyle.pdf\n",
      " - data\\Adult-Guide-to-an-Active-Healthy-Lifestyle.pdf\n",
      " - data\\how-can-i-make-lifestyle-healthier.pdf\n",
      " - data\\nnm_tipsheet.pdf\n",
      " - data\\PAG_ExecutiveSummary.pdf\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 1: DOCUMENT DISCOVERY\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Understand how to locate and validate data sources\n",
    "\n",
    "# Define the path to your PDF directory\n",
    "# TODO for students: Create a 'data' folder and add your PDF documents\n",
    "\n",
    "data_dir = \"./data\"\n",
    "\n",
    "# Find all PDF files in the directory recursively\n",
    "# This uses Path.rglob() to search through all subdirectories\n",
    "\n",
    "pdf_files = [str(p) for p in Path(data_dir).rglob(\"*.pdf\") if p.is_file()]\n",
    "\n",
    "# Validation: Always check if your data exists before processing\n",
    "if not pdf_files:\n",
    "    print(f\"No PDFs found in {data_dir}. Please add your PDFs and update the `data_dir` variable.\")\n",
    "    print(\"WORKSHOP TIP: Create the './data' folder and add at least one PDF document\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found {len(pdf_files)} PDF(s):\")\n",
    "    for f in pdf_files:\n",
    "        print(f\" - {f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4685b9f-1040-4b11-b384-aa594eeb4939",
   "metadata": {},
   "source": [
    "### Why choose this topic?\n",
    "The chosen topic is Health, Fitness, and Wellbeing, focusing on practical strategies for maintaining a balanced lifestyle. The selected documents cover nutrition, physical activity, mental wellness, and overall healthy habits. These materials provide clear, structured guidance suitable for text analysis and processing. This domain allows testing the LLM‚Äôs ability to handle real-world, instructional content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c4aae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PART 2: DOCUMENT LOADING & TEXT CHUNKING\n",
      "==================================================\n",
      "\n",
      "üìÑ Processing: 10-Tips-Healthy-Lifestyle.pdf\n",
      "‚úÖ Loaded 2 pages from 10-Tips-Healthy-Lifestyle.pdf\n",
      "\n",
      "üìÑ Processing: Adult-Guide-to-an-Active-Healthy-Lifestyle.pdf\n",
      "‚úÖ Loaded 18 pages from Adult-Guide-to-an-Active-Healthy-Lifestyle.pdf\n",
      "\n",
      "üìÑ Processing: how-can-i-make-lifestyle-healthier.pdf\n",
      "‚úÖ Loaded 2 pages from how-can-i-make-lifestyle-healthier.pdf\n",
      "\n",
      "üìÑ Processing: nnm_tipsheet.pdf\n",
      "‚úÖ Loaded 1 pages from nnm_tipsheet.pdf\n",
      "\n",
      "üìÑ Processing: PAG_ExecutiveSummary.pdf\n",
      "‚úÖ Loaded 7 pages from PAG_ExecutiveSummary.pdf\n",
      "\n",
      "üìä SUMMARY: Total pages loaded: 30\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 2: DOCUMENT LOADING AND PREPROCESSING\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Transform unstructured documents into structured data\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PART 2: DOCUMENT LOADING & TEXT CHUNKING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Initialize document storage\n",
    "documents = []\n",
    "\n",
    "# Process each PDF file\n",
    "for file_path in pdf_files:\n",
    "    try:\n",
    "        print(f\"\\nüìÑ Processing: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # PyPDFLoader: Specialized for PDF documents\n",
    "        # WORKSHOP NOTE: Different loaders exist for different file types\n",
    "        # (TextLoader, CSVLoader, JSONLoader, etc.)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        \n",
    "        # Load documents - each page becomes a separate document\n",
    "        docs = loader.load()\n",
    "        \n",
    "        # Add source metadata for traceability\n",
    "        # WORKSHOP TIP: Metadata is crucial for citation and verification\n",
    "        for doc in docs:\n",
    "            doc.metadata[\"source\"] = os.path.basename(file_path)\n",
    "            \n",
    "        documents.extend(docs)\n",
    "        print(f\"‚úÖ Loaded {len(docs)} pages from {os.path.basename(file_path)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file_path}: {e}\")\n",
    "        print(\"WORKSHOP TIP: Check file permissions and format compatibility\")\n",
    "\n",
    "print(f\"\\nüìä SUMMARY: Total pages loaded: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36d874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing config: Small chunks\n",
      "==================================================\n",
      "üîß Chunking Configuration:\n",
      "   - Chunk size: 400\n",
      "   - Chunk overlap: 200\n",
      "Total chunks created: 234\n",
      "Average chunk length: 360 characters\n",
      "Sample preview: 10 TIPS FOR MAINTAINING A HEALTHY  LIFESTYLE AND BODY WEIGHT  Yiqing Song, Professor of Epidemiology...\n",
      "\n",
      "==================================================\n",
      "Testing config: Large chunks\n",
      "==================================================\n",
      "üîß Chunking Configuration:\n",
      "   - Chunk size: 1200\n",
      "   - Chunk overlap: 50\n",
      "Total chunks created: 58\n",
      "Average chunk length: 871 characters\n",
      "Sample preview: 10 TIPS FOR MAINTAINING A HEALTHY  LIFESTYLE AND BODY WEIGHT  Yiqing Song, Professor of Epidemiology...\n",
      "\n",
      "‚úÖ Based on total chunks, average length, and preview readability, choose the configuration that balances context with chunk count. For your Health PDFs, large chunks (1200/50) usually work best.\n"
     ]
    }
   ],
   "source": [
    "#CHUNKING \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Two chunking configurations to test\n",
    "configs = [\n",
    "    {\"name\": \"Small chunks\", \"chunk_size\": 400, \"chunk_overlap\": 200},\n",
    "    {\"name\": \"Large chunks\", \"chunk_size\": 1200, \"chunk_overlap\": 50}\n",
    "]\n",
    "\n",
    "# Loop through each config and split documents\n",
    "for cfg in configs:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Testing config: {cfg['name']}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=cfg[\"chunk_size\"],\n",
    "        chunk_overlap=cfg[\"chunk_overlap\"],\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.split_documents(documents)\n",
    "    \n",
    "    # Add metadata for each chunk\n",
    "    for i, text in enumerate(chunks):\n",
    "        text.metadata[\"chunk_id\"] = i\n",
    "        text.metadata[\"chunk_length\"] = len(text.page_content)\n",
    "        text.metadata[\"preview\"] = text.page_content[:50].replace(\"\\n\", \" \")\n",
    "    \n",
    "    total_chunks = len(chunks)\n",
    "    avg_len = sum(len(c.page_content) for c in chunks)/total_chunks if total_chunks else 0\n",
    "    sample_preview = chunks[0].page_content[:100].replace(\"\\n\",\" \") if chunks else \"N/A\"\n",
    "    \n",
    "    print(f\"üîß Chunking Configuration:\")\n",
    "    print(f\"   - Chunk size: {cfg['chunk_size']}\")\n",
    "    print(f\"   - Chunk overlap: {cfg['chunk_overlap']}\")\n",
    "    print(f\"Total chunks created: {total_chunks}\")\n",
    "    print(f\"Average chunk length: {avg_len:.0f} characters\")\n",
    "    print(f\"Sample preview: {sample_preview}...\")\n",
    "\n",
    "# Recommendation:\n",
    "print(\"\\n‚úÖ Based on total chunks, average length, and preview readability, choose the configuration that balances context with chunk count. For your Health PDFs, large chunks (1200/50) usually work best.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4734075-43f3-4a3d-9820-f8169fa153c3",
   "metadata": {},
   "source": [
    "### Which chunking settings worked better and why?\n",
    "\n",
    " Two configurations were tested: small chunks (400/200) and large chunks (1200/50). Small chunks created 234 short, overlapping chunks that fragmented context, while large chunks produced 58 well-structured chunks with sufficient context and minimal redundancy. Therefore, the large chunk settings were chosen for better readability and more effective LLM processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee7aff0-4bdb-47b3-91f7-a2b86efefd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PART 4: VECTOR EMBEDDINGS & KNOWLEDGE BASE\n",
      "==================================================\n",
      "üß† Initializing embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandana M\\AppData\\Local\\Temp\\ipykernel_16980\\3699595364.py:15: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model loaded\n",
      "\n",
      "üóÑÔ∏è Creating vector database...\n",
      "‚úÖ Vector database created and saved to disk\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 4: EMBEDDINGS AND VECTOR STORE\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Convert text to vectors for semantic search\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PART 4: VECTOR EMBEDDINGS & KNOWLEDGE BASE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "print(\"üß† Initializing embedding model...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"‚úÖ Embedding model loaded\")\n",
    "\n",
    "# Create health documents\n",
    "texts = [\n",
    "    Document(page_content=\"Life's Essential 8: Eat better, be active, quit tobacco, get healthy sleep.\", metadata={\"source\": \"health_guide.pdf\"}),\n",
    "    Document(page_content=\"150 minutes moderate or 75 minutes vigorous activity per week.\", metadata={\"source\": \"health_guide.pdf\"}),\n",
    "    Document(page_content=\"Adults need 7-9 hours of sleep daily.\", metadata={\"source\": \"health_guide.pdf\"}),\n",
    "    Document(page_content=\"Eat more vegetables, fruits, whole grains.\", metadata={\"source\": \"health_guide.pdf\"})\n",
    "]\n",
    "\n",
    "print(\"\\nüóÑÔ∏è Creating vector database...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_clinicaltrial_db\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vector database created and saved to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b23b2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PART 5: RETRIEVAL CONFIGURATION\n",
      "==================================================\n",
      "üîç Retrieval Configuration:\n",
      "   - Strategy: MMR\n",
      "   - Documents returned: 5\n",
      "   - Initial candidates: 10\n",
      "   - Relevance vs Diversity balance: 0.7\n",
      "\n",
      "Question: What are some tips for maintaining a healthy lifestyle?\n",
      "Chunk 1 (Source: health_guide.pdf):\n",
      "  Preview: Life's Essential 8: Eat better, be active, quit tobacco, get healthy sleep....\n",
      "\n",
      "Chunk 2 (Source: health_guide.pdf):\n",
      "  Preview: 150 minutes moderate or 75 minutes vigorous activity per week....\n",
      "\n",
      "Chunk 3 (Source: valdoria-country-profile.pdf):\n",
      "  Preview: Healthcare system modernization\n",
      "Social inclusion programs\n",
      "Youth retention strategies\n",
      "Environmental G...\n",
      "\n",
      "\n",
      "Question: How much exercise should an adult get each week?\n",
      "Chunk 1 (Source: health_guide.pdf):\n",
      "  Preview: 150 minutes moderate or 75 minutes vigorous activity per week....\n",
      "\n",
      "Chunk 2 (Source: health_guide.pdf):\n",
      "  Preview: Adults need 7-9 hours of sleep daily....\n",
      "\n",
      "Chunk 3 (Source: health_guide.pdf):\n",
      "  Preview: Eat more vegetables, fruits, whole grains....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 5: RETRIEVAL CONFIGURATION\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Configure optimal document retrieval\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PART 5: RETRIEVAL CONFIGURATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create retriever with optimized settings\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",       # Use Maximum Marginal Relevance\n",
    "    search_kwargs={\n",
    "        \"k\": 3,              # Return top 3 chunks per query\n",
    "        \"fetch_k\": 10,       # Consider top 10 candidates before MMR\n",
    "        \"lambda_mult\": 0.5   # 0.5 relevance / 0.3 diversity\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"üîç Retrieval Configuration:\")\n",
    "print(f\"   - Strategy: MMR\")\n",
    "print(f\"   - Documents returned: 5\")\n",
    "print(f\"   - Initial candidates: 10\")\n",
    "print(f\"   - Relevance vs Diversity balance: 0.7\")\n",
    "\n",
    "# Test retrieval with 2 sample questions\n",
    "questions = [\n",
    "    \"What are some tips for maintaining a healthy lifestyle?\",\n",
    "    \"How much exercise should an adult get each week?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    results = retriever.get_relevant_documents(q)\n",
    "    print(f\"\\nQuestion: {q}\")\n",
    "    for i, r in enumerate(results):\n",
    "        print(f\"Chunk {i+1} (Source: {r.metadata.get('source','Unknown')}):\")\n",
    "        print(f\"  Preview: {r.page_content[:100]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef667008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PART 6: LANGUAGE MODEL SETUP\n",
      "==================================================\n",
      "üìã PREREQUISITE CHECK:\n",
      "   1. Install Ollama: https://ollama.ai/\n",
      "   2. Run: ollama pull phi3:mini\n",
      "   3. Verify: ollama list\n",
      "\n",
      "üß™ Testing LLM connection...\n",
      "‚úÖ LLM Response: The sum of 2 and 2 is 4. This simple arithmetic problem has a fixed answer, which can be easily calculated by adding the two numbers together. In this case:\n",
      "\n",
      "2 + 2 = 4\n",
      "‚úÖ Language model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 6: LLM INTEGRATION\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Connect local language model for generation\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PART 6: LANGUAGE MODEL SETUP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# PREREQUISITE: Install Ollama and pull a model\n",
    "print(\"üìã PREREQUISITE CHECK:\")\n",
    "print(\"   1. Install Ollama: https://ollama.ai/\")\n",
    "print(\"   2. Run: ollama pull phi3:mini\")\n",
    "print(\"   3. Verify: ollama list\")\n",
    "\n",
    "\n",
    "try:\n",
    "    llm = Ollama(\n",
    "        model=\"phi3:mini\",    # WORKSHOP NOTE: Lightweight model for laptops\n",
    "        temperature=0.2,      # Low temperature = more deterministic responses\n",
    "        num_thread=2,         # Adjust based on your CPU cores\n",
    "    )\n",
    "    \n",
    "    # Test LLM connection\n",
    "    print(\"\\nüß™ Testing LLM connection...\")\n",
    "    test_response = llm.invoke(\"What is 2+2?\")\n",
    "    print(f\"‚úÖ LLM Response: {test_response}\")\n",
    "    print(\"‚úÖ Language model initialized successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM Connection Failed: {e}\")\n",
    "    print(\"WORKSHOP TIP: Ensure Ollama is running and phi3:mini is installed\")\n",
    "    # TODO: Add fallback or alternative model suggestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e66e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PART 7: PROMPT ENGINEERING FOR GROUNDING\n",
      "==================================================\n",
      "‚úÖ Prompt template created with grounding instructions\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 7: PROMPT ENGINEERING\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Design prompts that enforce grounding\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PART 7: PROMPT ENGINEERING FOR GROUNDING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# CONCEPT: Prompt engineering for RAG\n",
    "# - Explicit instructions prevent hallucination\n",
    "# - Structure ensures consistent output format\n",
    "# - Citations enable verification\n",
    "\n",
    "# Enhanced prompt template for better factual retrieval\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a precise document analyst. Your task is to answer questions STRICTLY based on the provided context.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "1. ONLY use information explicitly stated in the context below\n",
    "2. If the context doesn't contain the answer, respond: \"The provided documents do not contain information to answer this question.\"\n",
    "3. Always cite which document/source your answer comes from\n",
    "4. Do not make inferences beyond what is directly stated\n",
    "5. If multiple sources contradict each other, mention the contradiction\n",
    "6. Use exact quotes when possible, enclosed in quotation marks\n",
    "7. For factual questions (like currency, population, etc.), scan ALL context carefully\n",
    "\n",
    "\n",
    "Context Documents:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Requirements for your answer:\n",
    "- Start with the most relevant source\n",
    "- Use direct quotes where applicable\n",
    "- Clearly separate facts from different sources\n",
    "- Look for keywords related to the question (currency, money, dollar, etc.)\n",
    "- End with source citations\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "print(\"‚úÖ Prompt template created with grounding instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b263dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PART 8: RAG CHAIN ASSEMBLY\n",
      "==================================================\n",
      "‚úÖ RAG chain assembled successfully!\n",
      "   Components connected: Retriever ‚Üí LLM ‚Üí Response\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 8: RAG CHAIN ASSEMBLY\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Combine all components into a working system\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PART 8: RAG CHAIN ASSEMBLY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",    # WORKSHOP NOTE: \"stuff\" = include all context in prompt\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": PROMPT,\n",
    "        \"document_separator\": \"\\n\\n--- SOURCE DOCUMENT ---\\n\\n\"\n",
    "    },\n",
    "    return_source_documents=True,  # Essential for verification\n",
    "    verbose=False  # WORKSHOP TIP: Set to True for debugging\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG chain assembled successfully!\")\n",
    "print(\"   Components connected: Retriever ‚Üí LLM ‚Üí Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78822001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 9: ANSWER VALIDATION SYSTEM\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Implement quality control for RAG responses\n",
    "\n",
    "def validate_answer(answer, source_docs):\n",
    "    \"\"\"\n",
    "    WORKSHOP FUNCTION: Answer Quality Assessment\n",
    "    \n",
    "    PURPOSE: Detect potential hallucinations and assess grounding quality\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - answer: Generated response from RAG system\n",
    "    - source_docs: Retrieved documents used for context\n",
    "    \n",
    "    RETURNS:\n",
    "    - confidence_score: Float between 0.0 and 1.0\n",
    "    - warnings: List of quality issues detected\n",
    "    \"\"\"\n",
    "    answer_lower = answer.lower()\n",
    "    \n",
    "    # Define hallucination indicators\n",
    "    # WORKSHOP EXERCISE: Add more phrases students might identify\n",
    "    hallucination_phrases = [\n",
    "        \"i think\", \"probably\", \"likely\", \"it seems\", \"perhaps\", \n",
    "        \"generally speaking\", \"typically\", \"usually\", \"in most cases\"\n",
    "    ]\n",
    "    \n",
    "    confidence_score = 1.0\n",
    "    warnings = []\n",
    "    \n",
    "    # Check for uncertain language\n",
    "    for phrase in hallucination_phrases:\n",
    "        if phrase in answer_lower:\n",
    "            confidence_score -= 0.2\n",
    "            warnings.append(f\"Uncertain language detected: '{phrase}'\")\n",
    "    \n",
    "    # Verify source citation\n",
    "    has_citations = any(doc.metadata['source'].lower() in answer_lower for doc in source_docs)\n",
    "    if not has_citations:\n",
    "        confidence_score -= 0.3\n",
    "        warnings.append(\"Answer does not reference source documents\")\n",
    "    \n",
    "    return max(0.0, confidence_score), warnings\n",
    "\n",
    "def ask_question_with_validation(question):\n",
    "    \"\"\"\n",
    "    WORKSHOP FUNCTION: Complete RAG Query with Validation\n",
    "    \n",
    "    This function demonstrates the full RAG pipeline:\n",
    "    1. Question input\n",
    "    2. Document retrieval\n",
    "    3. Answer generation\n",
    "    4. Quality validation\n",
    "    5. Source verification\n",
    "    \"\"\"\n",
    "    print(f\"ü§î Question: {question}\")\n",
    "    print(\"\\nüîç Retrieving relevant information...\")\n",
    "    \n",
    "    # Execute RAG pipeline\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    answer = result[\"result\"]\n",
    "    source_docs = result[\"source_documents\"]\n",
    "    \n",
    "    # Validate response quality\n",
    "    confidence, warnings = validate_answer(answer, source_docs)\n",
    "    \n",
    "    # Display results with educational annotations\n",
    "    print(\"\\nüìù Answer:\")\n",
    "    print(\"=\"*50)\n",
    "    print(answer)\n",
    "    \n",
    "    # Quality assessment\n",
    "    print(f\"\\nüìä Quality Assessment:\")\n",
    "    print(f\"   Confidence Score: {confidence:.2f}/1.0\")\n",
    "    \n",
    "    if confidence >= 0.8:\n",
    "        print(\"   ‚úÖ HIGH QUALITY: Well-grounded response\")\n",
    "    elif confidence >= 0.6:\n",
    "        print(\"   ‚ö†Ô∏è  MEDIUM QUALITY: Review recommended\")\n",
    "    else:\n",
    "        print(\"   ‚ùå LOW QUALITY: Potential hallucination detected\")\n",
    "    \n",
    "    if warnings:\n",
    "        print(\"\\n‚ö†Ô∏è  Quality Warnings:\")\n",
    "        for warning in warnings:\n",
    "            print(f\"   ‚Ä¢ {warning}\")\n",
    "    \n",
    "    # Enhanced source verification with keyword analysis\n",
    "    print(f\"\\nüìö Retrieved Sources ({len(source_docs)} documents):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    question_keywords = set(question.lower().split())\n",
    "    \n",
    "    for i, doc in enumerate(source_docs):\n",
    "        content_keywords = set(doc.page_content.lower().split())\n",
    "        keyword_overlap = question_keywords.intersection(content_keywords)\n",
    "        \n",
    "        print(f\"{i+1}. Source: {doc.metadata['source']}\")\n",
    "        print(f\"   Page: {doc.metadata.get('page', 'Unknown')}\")\n",
    "        print(f\"   Keyword overlap: {list(keyword_overlap)}\")\n",
    "        print(f\"   Content: {doc.page_content[:200]}...\")\n",
    "        print()\n",
    "    \n",
    "    # Suggest improvements if answer is not found\n",
    "    if \"do not contain information\" in answer.lower():\n",
    "        print(\"\\nüí° TROUBLESHOOTING SUGGESTIONS:\")\n",
    "        print(\"1. Check if your question keywords appear in the documents\")\n",
    "        print(\"2. Try rephrasing the question with different terms\")\n",
    "        print(\"3. Verify the PDF content was properly extracted\")\n",
    "        print(\"4. Consider if the information spans multiple chunks\")\n",
    "        \n",
    "        # Try alternative search terms\n",
    "        if \"currency\" in question.lower():\n",
    "            alt_terms = [\"money\", \"dollar\", \"economic\", \"financial\", \"payment\"]\n",
    "            print(f\"\\nüîÑ Trying alternative search terms: {alt_terms}\")\n",
    "            for term in alt_terms:\n",
    "                alt_docs = vectorstore.similarity_search(term, k=3)\n",
    "                if alt_docs:\n",
    "                    print(f\"\\n   Found content for '{term}':\")\n",
    "                    for doc in alt_docs[:1]:  # Show first match\n",
    "                        print(f\"   {doc.page_content[:100]}...\")\n",
    "    \n",
    "    return result, confidence, warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b72253ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "WORKSHOP DEMONSTRATION: TESTING THE RAG SYSTEM\n",
      "================================================================================\n",
      "üß™ RUNNING SAMPLE QUERY...\n",
      "ü§î Question: How much sleep do adults need?\n",
      "\n",
      "üîç Retrieving relevant information...\n",
      "\n",
      "üìù Answer:\n",
      "==================================================\n",
      "Adults need \"7-9 hours of sleep daily\" as stated in Life's Essential 8. This information is sourced from Source Document [Life's Essential 8]. No other document provides specific details on the required amount of adult sleep, thus we rely solely on this source for our answer. (No contradiction found)\n",
      "\n",
      "üìä Quality Assessment:\n",
      "   Confidence Score: 0.70/1.0\n",
      "   ‚ö†Ô∏è  MEDIUM QUALITY: Review recommended\n",
      "\n",
      "‚ö†Ô∏è  Quality Warnings:\n",
      "   ‚Ä¢ Answer does not reference source documents\n",
      "\n",
      "üìö Retrieved Sources (5 documents):\n",
      "------------------------------------------------------------\n",
      "1. Source: health_guide.pdf\n",
      "   Page: Unknown\n",
      "   Keyword overlap: ['sleep', 'adults']\n",
      "   Content: Adults need 7-9 hours of sleep daily....\n",
      "\n",
      "2. Source: health_guide.pdf\n",
      "   Page: Unknown\n",
      "   Keyword overlap: []\n",
      "   Content: 150 minutes moderate or 75 minutes vigorous activity per week....\n",
      "\n",
      "3. Source: health_guide.pdf\n",
      "   Page: Unknown\n",
      "   Keyword overlap: []\n",
      "   Content: Life's Essential 8: Eat better, be active, quit tobacco, get healthy sleep....\n",
      "\n",
      "4. Source: valdoria-country-profile.pdf\n",
      "   Page: 2\n",
      "   Keyword overlap: []\n",
      "   Content: branches:\n",
      "Population\n",
      "0\u000014 years: 16.8%\n",
      "15\u000064 years: 67.4%\n",
      "65+ years: 15.8%\n",
      "Ethnicity and Language\n",
      "Valdorian: 82.4%\n",
      "Hungarian: 7.2%\n",
      "Croatian: 4.1%\n",
      "Austrian: 2.8%\n",
      "Slovenian: 1.9%\n",
      "Other: 1.6%\n",
      "Religion\n",
      "Ro...\n",
      "\n",
      "5. Source: valdoria-country-profile.pdf\n",
      "   Page: 2\n",
      "   Keyword overlap: []\n",
      "   Content: branches:\n",
      "Population\n",
      "0\u000014 years: 16.8%\n",
      "15\u000064 years: 67.4%\n",
      "65+ years: 15.8%\n",
      "Ethnicity and Language\n",
      "Valdorian: 82.4%\n",
      "Hungarian: 7.2%\n",
      "Croatian: 4.1%\n",
      "Austrian: 2.8%\n",
      "Slovenian: 1.9%\n",
      "Other: 1.6%\n",
      "Religion\n",
      "Ro...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 10: HANDS-ON TESTING\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Test the complete RAG system\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WORKSHOP DEMONSTRATION: TESTING THE RAG SYSTEM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sample question for demonstration\n",
    "# WORKSHOP INSTRUCTION: Students should modify this question\n",
    "question = \"How much sleep do adults need?\"\n",
    "\n",
    "print(\"üß™ RUNNING SAMPLE QUERY...\")\n",
    "result, confidence, warnings = ask_question_with_validation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0674c748-ad76-4cc8-8cca-ebc93d6d60ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "WORKSHOP DEMONSTRATION: TESTING THE RAG SYSTEM\n",
      "================================================================================\n",
      "üß™ RUNNING SAMPLE QUERY...\n",
      "ü§î Question: How much physical activity should adults get per week?\n",
      "\n",
      "üîç Retrieving relevant information...\n",
      "\n",
      "üìù Answer:\n",
      "==================================================\n",
      "According to Source Document [1], adults should get \"75 minutes of vigorous activity per week\" or alternatively \"150 minutes of moderate activity.\" These recommendations are based on the guidelines provided in that document. There is no mention of physical activities related to currency, money, dollar, etc., as these terms do not appear within the context documents and therefore cannot be addressed herein.\n",
      "\n",
      "References: [1]\n",
      "\n",
      "üìä Quality Assessment:\n",
      "   Confidence Score: 0.70/1.0\n",
      "   ‚ö†Ô∏è  MEDIUM QUALITY: Review recommended\n",
      "\n",
      "‚ö†Ô∏è  Quality Warnings:\n",
      "   ‚Ä¢ Answer does not reference source documents\n",
      "\n",
      "üìö Retrieved Sources (3 documents):\n",
      "------------------------------------------------------------\n",
      "1. Source: health_guide.pdf\n",
      "   Page: Unknown\n",
      "   Keyword overlap: ['activity', 'per']\n",
      "   Content: 150 minutes moderate or 75 minutes vigorous activity per week....\n",
      "\n",
      "2. Source: health_guide.pdf\n",
      "   Page: Unknown\n",
      "   Keyword overlap: ['adults']\n",
      "   Content: Adults need 7-9 hours of sleep daily....\n",
      "\n",
      "3. Source: valdoria-country-profile.pdf\n",
      "   Page: 2\n",
      "   Keyword overlap: []\n",
      "   Content: branches:\n",
      "Population\n",
      "0\u000014 years: 16.8%\n",
      "15\u000064 years: 67.4%\n",
      "65+ years: 15.8%\n",
      "Ethnicity and Language\n",
      "Valdorian: 82.4%\n",
      "Hungarian: 7.2%\n",
      "Croatian: 4.1%\n",
      "Austrian: 2.8%\n",
      "Slovenian: 1.9%\n",
      "Other: 1.6%\n",
      "Religion\n",
      "Ro...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP ACTIVITY 10: HANDS-ON TESTING\n",
    "# ========================================================================\n",
    "# LEARNING OBJECTIVE: Test the complete RAG system\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WORKSHOP DEMONSTRATION: TESTING THE RAG SYSTEM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sample question for demonstration\n",
    "# WORKSHOP INSTRUCTION: Students should modify this question\n",
    "question = \"How much physical activity should adults get per week?\"\n",
    "\n",
    "print(\"üß™ RUNNING SAMPLE QUERY...\")\n",
    "result, confidence, warnings = ask_question_with_validation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "090bd312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéì WORKSHOP COMPLETE! RAG SYSTEM READY FOR EXPERIMENTATION\n",
      "================================================================================\n",
      "\n",
      "EXPERIMENT IDEAS FOR STUDENTS:\n",
      "1. Try different chunk sizes (400, 800, 1200)\n",
      "2. Compare similarity vs MMR retrieval\n",
      "3. Adjust retrieval parameters (k, fetch_k, lambda_mult)\n",
      "4. Modify the prompt template\n",
      "5. Test with different types of questions\n",
      "6. Add your own validation criteria\n",
      "\n",
      "üîß DEBUGGING TOOLS:\n",
      "- Use debug_retrieval(question, vectorstore) to see what's retrieved\n",
      "- Use manual_search('currency', vectorstore) to find specific terms\n",
      "- Check similarity scores to understand retrieval quality\n",
      "\n",
      "HAPPY LEARNING! üöÄ\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# WORKSHOP CONCLUSION: INTERACTIVE SESSION\n",
    "# ========================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéì WORKSHOP COMPLETE! RAG SYSTEM READY FOR EXPERIMENTATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nEXPERIMENT IDEAS FOR STUDENTS:\")\n",
    "print(\"1. Try different chunk sizes (400, 800, 1200)\")\n",
    "print(\"2. Compare similarity vs MMR retrieval\")\n",
    "print(\"3. Adjust retrieval parameters (k, fetch_k, lambda_mult)\")\n",
    "print(\"4. Modify the prompt template\")\n",
    "print(\"5. Test with different types of questions\")\n",
    "print(\"6. Add your own validation criteria\")\n",
    "print(\"\\nüîß DEBUGGING TOOLS:\")\n",
    "print(\"- Use debug_retrieval(question, vectorstore) to see what's retrieved\")\n",
    "print(\"- Use manual_search('currency', vectorstore) to find specific terms\")\n",
    "print(\"- Check similarity scores to understand retrieval quality\")\n",
    "print(\"\\nHAPPY LEARNING! üöÄ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd9c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
